{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Projects/text-classifer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "# get topic categories\n",
    "with open(os.path.join('data', 'all-topics-strings.lc.txt')) as t_file:\n",
    "    topic_lst = [category.strip().lower() for category in t_file.readlines()]\n",
    "print(topic_lst)\n",
    "print(len(topic_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file data/reut2-000.sgm\n",
      "processing file data/reut2-001.sgm\n",
      "processing file data/reut2-002.sgm\n",
      "processing file data/reut2-003.sgm\n",
      "processing file data/reut2-004.sgm\n",
      "processing file data/reut2-005.sgm\n",
      "processing file data/reut2-006.sgm\n",
      "processing file data/reut2-007.sgm\n",
      "processing file data/reut2-008.sgm\n",
      "processing file data/reut2-009.sgm\n",
      "processing file data/reut2-010.sgm\n",
      "processing file data/reut2-011.sgm\n",
      "processing file data/reut2-012.sgm\n",
      "processing file data/reut2-013.sgm\n",
      "processing file data/reut2-014.sgm\n",
      "processing file data/reut2-015.sgm\n",
      "processing file data/reut2-016.sgm\n",
      "processing file data/reut2-017.sgm\n",
      "processing file data/reut2-018.sgm\n",
      "processing file data/reut2-019.sgm\n",
      "processing file data/reut2-020.sgm\n",
      "processing file data/reut2-021.sgm\n",
      "train:  7780\n",
      "test:  3022\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import xml.sax.saxutils as saxutils\n",
    "import codecs\n",
    "number_of_files = 22\n",
    "_train_text_lst, _train_label_lst, _test_text_lst, _test_label_lst = [], [], [], []\n",
    "\n",
    "\n",
    "def strip_tags(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "\n",
    "for idx in range(number_of_files):\n",
    "    file_path = os.path.join('data', 'reut2-0{}.sgm'.format('0{}'.format(idx) if idx < 10 else idx))\n",
    "    print('processing file {}'.format(file_path))\n",
    "    with codecs.open(file_path, 'r', encoding='UTF8', errors='replace') as f:        \n",
    "        content = BeautifulSoup(f.read().lower(), 'html.parser')\n",
    "        for doc in content('reuters'):            \n",
    "            doc_id = doc['newid']\n",
    "            doc_split = doc['lewissplit']            \n",
    "            doc_topics = [strip_tags(str(topic)) for topic in doc.topics.contents]\n",
    "            if not doc_topics:\n",
    "                continue\n",
    "            # to debug\n",
    "            # print(doc_id, doc_split, doc_topics)\n",
    "            # raise\n",
    "            doc_body = saxutils.unescape(strip_tags(str(doc('text')[0].body)).replace('reuter\\n&#3;', ''))            \n",
    "            if doc_split == 'train':\n",
    "                _train_text_lst.append(doc_body); _train_label_lst.append(doc_topics)\n",
    "            elif doc_split == 'test':\n",
    "                _test_text_lst.append(doc_body); _test_label_lst.append(doc_topics)\n",
    "print('train: ', len(_train_text_lst))\n",
    "print('test: ', len(_test_text_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('austral', 0), ('bfr', 0), ('castor-meal', 0), ('cotton-meal', 0), ('cottonseed', 0), ('drachma', 0), ('escudo', 0), ('f-cattle', 0), ('ffr', 0), ('flaxseed', 0), ('groundnut-meal', 0), ('hk', 0), ('lupin', 0), ('mexpeso', 0), ('palm-meal', 0), ('sfr', 0), ('silk', 0), ('singdlr', 0), ('tung', 0), ('tung-oil', 0), ('castor-oil', 1), ('castorseed', 1), ('citruspulp', 1), ('corn-oil', 1), ('cotton-oil', 1), ('cruzado', 1), ('dkr', 1), ('groundnut-oil', 1), ('lin-meal', 1), ('lin-oil', 1), ('lit', 1), ('nkr', 1), ('peseta', 1), ('rape-meal', 1), ('red-bean', 1), ('ringgit', 1), ('rupiah', 1), ('rye', 1), ('skr', 1), ('sun-meal', 1), ('copra-cake', 2), ('cornglutenfeed', 2), ('dfl', 2), ('fishmeal', 2), ('linseed', 2), ('naphtha', 2), ('nzdlr', 2), ('palladium', 2), ('palmkernel', 2), ('rand', 2), ('wool', 2), ('can', 3), ('cpu', 3), ('pork-belly', 3), ('potato', 3), ('propane', 3), ('saudriyal', 3), ('tapioca', 3), ('austdlr', 4), ('coconut', 4), ('coconut-oil', 4), ('jet', 4), ('plywood', 4), ('groundnut', 5), ('instal-debt', 5), ('inventories', 5), ('platinum', 5), ('rape-oil', 5), ('sun-oil', 5), ('l-cattle', 6), ('nickel', 8), ('oat', 8), ('income', 9), ('tea', 9), ('dmk', 10), ('lumber', 10), ('sunseed', 11), ('lei', 12), ('fuel', 13), ('soy-meal', 13), ('heat', 14), ('soy-oil', 14), ('lead', 15), ('hog', 16), ('housing', 16), ('orange', 16), ('strategic-metal', 16), ('stg', 17), ('rapeseed', 18), ('tin', 18), ('wpi', 19), ('pet-chem', 20), ('silver', 21), ('zinc', 21), ('retail', 23), ('sorghum', 24), ('meal-feed', 30), ('palm-oil', 30), ('alum', 35), ('rice', 35), ('barley', 37), ('rubber', 37), ('gas', 38), ('cotton', 39), ('iron-steel', 40), ('ipi', 41), ('yen', 45), ('jobs', 46), ('copper', 47), ('carcass', 50), ('cocoa', 55), ('reserves', 55), ('cpi', 69), ('bop', 75), ('livestock', 75), ('nat-gas', 75), ('soybean', 78), ('veg-oil', 87), ('gold', 94), ('gnp', 101), ('coffee', 111), ('oilseed', 124), ('sugar', 126), ('dlr', 131), ('money-supply', 140), ('corn', 183), ('ship', 198), ('wheat', 212), ('interest', 347), ('trade', 369), ('crude', 391), ('grain', 434), ('money-fx', 539), ('acq', 1650), ('earn', 2877)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAHVCAYAAABSeALaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBiDuAAAABiDuAAAABiDuAAAABvD/Af1omn62eCLjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8100d22f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot distribution of labels\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "train_topic_count = {topic: 0 for topic in topic_lst}\n",
    "for labels in _train_label_lst:   # try with test_label_lst\n",
    "    for t in labels:\n",
    "        train_topic_count[t] += 1\n",
    "sorted_topic_count = sorted(topic_count.items(), key=operator.itemgetter(1))\n",
    "print(sorted_topic_count)\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(range(len(topic_count)), list(topic_count.values()), align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove classes with few occurences\n",
    "topics_selected = [key for key in train_topic_count if train_topic_count[key] > 3]\n",
    "def remove_minor_class(text_lst, _label_lst, topics_selected):\n",
    "    label_lst = _label_lst.copy()\n",
    "    idx_selected = []    \n",
    "    for i, topics_sample in enumerate(label_lst):\n",
    "        intersect = list(set(topics_sample) & set(topics_selected))\n",
    "        if len(intersect) > 0:\n",
    "            idx_selected.append(i)\n",
    "            label_lst[i] = intersect\n",
    "    return idx_selected, label_lst\n",
    "\n",
    "# remove samples with few class occurences in training set\n",
    "train_idx_selected, train_label_lst = remove_minor_class(_train_text_lst, _train_label_lst, topics_selected)\n",
    "train_text_lst = [train_text_lst[i] for i in train_idx_selected]\n",
    "train_label_lst = [train_label_lst[i] for i in train_idx_selected]\n",
    "\n",
    "# remove samples with few class occurences in test set\n",
    "test_idx_selected, test_label_lst = remove_minor_class(_test_text_lst, _test_label_lst, topics_selected)\n",
    "test_text_lst = [test_text_lst[i] for i in test_idx_selected]\n",
    "test_label_lst = [test_label_lst[i] for i in test_idx_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7773, 77)\n",
      "(3016, 77)\n"
     ]
    }
   ],
   "source": [
    "# label transformer\n",
    "from sklearn import preprocessing\n",
    "label_binarizer = preprocessing.MultiLabelBinarizer(topics_selected)\n",
    "label_binarizer.fit(train_label_lst)\n",
    "# transform training label\n",
    "y_train = label_binarizer.transform(train_label_lst)\n",
    "print(y_train.shape)\n",
    "# transform testing label\n",
    "y_test = label_binarizer.transform(test_label_lst)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 23545)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "x_train = vect.fit_transform(train_text_lst)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model building + grid search + evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model, svm, naive_bayes, model_selection, metrics\n",
    "class LRModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('cls', OneVsRestClassifier(linear_model.LogisticRegression()))\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        \"cls__estimator__C\": [0.01, 0.1, 1],\n",
    "    }\n",
    "    \n",
    "class NBModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('cls', OneVsRestClassifier(naive_bayes.MultinomialNB(\n",
    "            fit_prior=True, class_prior=None))),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'cls__estimator__alpha': (1e-2, 1e-3)\n",
    "    }\n",
    "    \n",
    "class SVCModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('cls', OneVsRestClassifier(svm.LinearSVC())),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'cls__estimator__C': [0.01, 0.1, 1]        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "class XGBModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "        ('cls', OneVsRestClassifier(XGBClassifier())),\n",
    "    ])   \n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],        \n",
    "        'cls__estimator__max_depth': [3, 11],\n",
    "        'cls__estimator__subsample': [0.25, 0.5, 0.75],\n",
    "        'cls__estimator__colsample_bytree': [0.25, 0.5, 0.75]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.786701531565185, total=  36.9s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7443130118289354, total=  36.2s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7713448149505313, total=  40.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7780403562988548, total=  45.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7894148341408871, total=  49.3s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7722374429223744, total=  46.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7474010578150647, total=  53.5s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7939642324888226, total=  59.2s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7831166384021104, total=  38.6s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7666605470901414, total=  41.5s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.749005424954792, total=  50.5s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7415812591508052, total=  39.3s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.785137924563708, total=  45.2s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7713972201901974, total=  55.9s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7435242612185333, total=  58.0s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7774329012232974, total=  52.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7874251497005987, total=  49.9s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  4.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7427113702623906, total=  50.9s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7858439201451904, total=  53.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.8002961317786415, total=  57.1s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7626570915619391, total=  48.4s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7915993537964459, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.8038891946431846, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7592159683510159, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  6.1min\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7882076324832701, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.786813982974099, total=  56.7s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7630407690938223, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.8061674008810573, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7997775305895439, total=  50.0s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7559168925022584, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.8014760147601476, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7890371438874865, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7551867219917012, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  9.0min\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7861146266497919, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7907564542336161, total=  55.1s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.8, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7554671968190856, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.8019145802650959, total=  55.1s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7671184022824536, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.8078889700511321, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.8007854337736522, total= 1.4min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7646112600536192, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 12.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.792154039949613, total= 1.4min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.8108305890962313, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7678920262830758, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7931345980126469, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.8027387120651369, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7640086206896552, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.8085808580858085, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.793370563862367, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7584966732602051, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7959073774905762, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.8090959105079772, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 15.8min\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=3, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7637470893784704, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7708448371065709, total=  47.4s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7912457912457913, total=  58.9s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7511394712853237, total=  49.6s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7842639593908629, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.796883695047301, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7433369843008396, total=  59.2s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7762989972652689, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7991071428571429, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7538433713148852, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7666055045871558, total= 1.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 18.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7442286551850494, total=  47.1s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7921980495123782, total=  58.4s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.773674588665448, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7916120576671034, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7458553470577519, total=  59.3s\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7760102395319071, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7931937172774869, total= 1.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.25, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7462252137529561, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.779306549257017, total= 1.5min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7994801336799109, total= 1.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7612481857764877, total= 1.5min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7948164146868251, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.8090341535071612, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 23.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7575757575757576, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7884615384615384, total= 2.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.8113276940051488, total= 1.6min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7816091954022988, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7662244532090355, total= 1.9min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.8014157973174365, total= 1.4min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7510456446626659, total= 1.3min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7886915549111998, total= 1.5min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.8078981361874885, total= 1.8min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7528049221860297, total= 1.6min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.7880770628862233, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.8015578635014836, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.5, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3), score=0.757411424439624, total= 1.8min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 29.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.785531603945926, total= 1.6min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7995533221663874, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1), score=0.7581556406050665, total= 1.5min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.797260767705893, total= 2.0min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.8135219548043359, total= 1.9min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 2), score=0.7589204854193081, total= 1.8min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7905368516833486, total= 2.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.7689271618227486, total= 1.9min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7856099342585829, total= 1.8min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 3), score=0.8109902268117278, total= 2.1min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7979873276183376, total= 1.5min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 1), score=0.7578409919766593, total= 1.7min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.8043719896257874, total= 1.8min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7909338168631007, total= 2.2min\n",
      "[CV] cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 3) \n",
      "[CV]  cls__estimator__colsample_bytree=0.25, cls__estimator__max_depth=11, cls__estimator__subsample=0.75, vectorizer__max_df=0.75, vectorizer__ngram_range=(1, 2), score=0.7553133514986377, total= 1.9min\n",
      "[CV] cls__estimator__colsample_bytree=0.5, cls__estimator__max_depth=3, cls__estimator__subsample=0.25, vectorizer__max_df=0.5, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 36.6min\n",
      "/home/hieuhuynh/Apps/anaconda3/envs/tf-1.7.0-cpu/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "mid = 'XGBModel'\n",
    "pipeline, parameters = XGBModel.pipeline, XGBModel.parameters\n",
    "grid_search = model_selection.GridSearchCV(pipeline, parameters, scoring='f1_micro', cv=None, n_jobs=4, verbose=10)\n",
    "grid_search.fit(train_text_lst, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search.best_estimator_.steps)\n",
    "\n",
    "print(\"Perform best classifier on test data:\")\n",
    "best_clf = grid_search.best_estimator_\n",
    "predictions = best_clf.predict(test_text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(y_test, predictions, target_names=topics_selected)\n",
    "print(report)\n",
    "with(open(os.path.join(os.getcwd(), '{}.txt'.format(mid)), 'w')) as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
