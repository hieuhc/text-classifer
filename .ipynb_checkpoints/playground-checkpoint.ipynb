{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Projects/text-cls\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "# get topic categories\n",
    "with open(os.path.join('data', 'all-topics-strings.lc.txt')) as t_file:\n",
    "    topic_lst = [category.strip().lower() for category in t_file.readlines()]\n",
    "print(topic_lst)\n",
    "print(len(topic_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file data/reut2-000.sgm\n",
      "processing file data/reut2-001.sgm\n",
      "processing file data/reut2-002.sgm\n",
      "processing file data/reut2-003.sgm\n",
      "processing file data/reut2-004.sgm\n",
      "processing file data/reut2-005.sgm\n",
      "processing file data/reut2-006.sgm\n",
      "processing file data/reut2-007.sgm\n",
      "processing file data/reut2-008.sgm\n",
      "processing file data/reut2-009.sgm\n",
      "processing file data/reut2-010.sgm\n",
      "processing file data/reut2-011.sgm\n",
      "processing file data/reut2-012.sgm\n",
      "processing file data/reut2-013.sgm\n",
      "processing file data/reut2-014.sgm\n",
      "processing file data/reut2-015.sgm\n",
      "processing file data/reut2-016.sgm\n",
      "processing file data/reut2-017.sgm\n",
      "processing file data/reut2-018.sgm\n",
      "processing file data/reut2-019.sgm\n",
      "processing file data/reut2-020.sgm\n",
      "processing file data/reut2-021.sgm\n",
      "train:  7780\n",
      "test:  3022\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import xml.sax.saxutils as saxutils\n",
    "import codecs\n",
    "number_of_files = 22\n",
    "_train_text_lst, _train_label_lst, _test_text_lst, _test_label_lst = [], [], [], []\n",
    "\n",
    "\n",
    "def strip_tags(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "\n",
    "for idx in range(number_of_files):\n",
    "    file_path = os.path.join('data', 'reut2-0{}.sgm'.format('0{}'.format(idx) if idx < 10 else idx))\n",
    "    print('processing file {}'.format(file_path))\n",
    "    with codecs.open(file_path, 'r', encoding='UTF8', errors='replace') as f:        \n",
    "        content = BeautifulSoup(f.read().lower(), 'html.parser')\n",
    "        for doc in content('reuters'):            \n",
    "            doc_id = doc['newid']\n",
    "            doc_split = doc['lewissplit']            \n",
    "            doc_topics = [strip_tags(str(topic)) for topic in doc.topics.contents]\n",
    "            if not doc_topics:\n",
    "                continue\n",
    "            # to debug\n",
    "            # print(doc_id, doc_split, doc_topics)\n",
    "            # raise\n",
    "            doc_body = saxutils.unescape(strip_tags(str(doc('text')[0].body)).replace('reuter\\n&#3;', ''))            \n",
    "            if doc_split == 'train':\n",
    "                _train_text_lst.append(doc_body); _train_label_lst.append(doc_topics)\n",
    "            elif doc_split == 'test':\n",
    "                _test_text_lst.append(doc_body); _test_label_lst.append(doc_topics)\n",
    "print('train: ', len(_train_text_lst))\n",
    "print('test: ', len(_test_text_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cottonseed', 0), ('castor-meal', 0), ('tung', 0), ('lupin', 0), ('f-cattle', 0), ('bfr', 0), ('silk', 0), ('mexpeso', 0), ('flaxseed', 0), ('singdlr', 0), ('sfr', 0), ('tung-oil', 0), ('groundnut-meal', 0), ('hk', 0), ('cotton-meal', 0), ('drachma', 0), ('austral', 0), ('ffr', 0), ('palm-meal', 0), ('escudo', 0), ('dkr', 1), ('rye', 1), ('ringgit', 1), ('castorseed', 1), ('lit', 1), ('citruspulp', 1), ('corn-oil', 1), ('cotton-oil', 1), ('rupiah', 1), ('peseta', 1), ('lin-meal', 1), ('lin-oil', 1), ('groundnut-oil', 1), ('sun-meal', 1), ('red-bean', 1), ('nkr', 1), ('rape-meal', 1), ('castor-oil', 1), ('cruzado', 1), ('skr', 1), ('cornglutenfeed', 2), ('naphtha', 2), ('nzdlr', 2), ('wool', 2), ('rand', 2), ('copra-cake', 2), ('fishmeal', 2), ('palmkernel', 2), ('palladium', 2), ('linseed', 2), ('dfl', 2), ('cpu', 3), ('pork-belly', 3), ('propane', 3), ('potato', 3), ('saudriyal', 3), ('can', 3), ('tapioca', 3), ('jet', 4), ('plywood', 4), ('coconut', 4), ('coconut-oil', 4), ('austdlr', 4), ('rape-oil', 5), ('inventories', 5), ('sun-oil', 5), ('groundnut', 5), ('instal-debt', 5), ('platinum', 5), ('l-cattle', 6), ('oat', 8), ('nickel', 8), ('income', 9), ('tea', 9), ('lumber', 10), ('dmk', 10), ('sunseed', 11), ('lei', 12), ('fuel', 13), ('soy-meal', 13), ('soy-oil', 14), ('heat', 14), ('lead', 15), ('hog', 16), ('strategic-metal', 16), ('housing', 16), ('orange', 16), ('stg', 17), ('tin', 18), ('rapeseed', 18), ('wpi', 19), ('pet-chem', 20), ('silver', 21), ('zinc', 21), ('retail', 23), ('sorghum', 24), ('meal-feed', 30), ('palm-oil', 30), ('alum', 35), ('rice', 35), ('barley', 37), ('rubber', 37), ('gas', 38), ('cotton', 39), ('iron-steel', 40), ('ipi', 41), ('yen', 45), ('jobs', 46), ('copper', 47), ('carcass', 50), ('cocoa', 55), ('reserves', 55), ('cpi', 69), ('bop', 75), ('livestock', 75), ('nat-gas', 75), ('soybean', 78), ('veg-oil', 87), ('gold', 94), ('gnp', 101), ('coffee', 111), ('oilseed', 124), ('sugar', 126), ('dlr', 131), ('money-supply', 140), ('corn', 183), ('ship', 198), ('wheat', 212), ('interest', 347), ('trade', 369), ('crude', 391), ('grain', 434), ('money-fx', 539), ('acq', 1650), ('earn', 2877)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNQAAAKaCAYAAAD2ygSvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b663fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot distribution of labels\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "train_topic_count = {topic: 0 for topic in topic_lst}\n",
    "for labels in _train_label_lst:   # try with test_label_lst\n",
    "    for t in labels:\n",
    "        train_topic_count[t] += 1\n",
    "sorted_topic_count = sorted(train_topic_count.items(), key=operator.itemgetter(1))\n",
    "print(sorted_topic_count)\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(range(len(train_topic_count)), list(train_topic_count.values()), align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove classes with few occurences\n",
    "topics_selected = [key for key in train_topic_count if train_topic_count[key] > 3]\n",
    "def remove_minor_class(text_lst, _label_lst, topics_selected):\n",
    "    label_lst = _label_lst.copy()\n",
    "    idx_selected = []    \n",
    "    for i, topics_sample in enumerate(label_lst):\n",
    "        intersect = list(set(topics_sample) & set(topics_selected))\n",
    "        if len(intersect) > 0:\n",
    "            idx_selected.append(i)\n",
    "            label_lst[i] = intersect\n",
    "    return idx_selected, label_lst\n",
    "\n",
    "# remove samples with few class occurences in training set\n",
    "train_idx_selected, train_label_lst = remove_minor_class(_train_text_lst, _train_label_lst, topics_selected)\n",
    "train_text_lst = [_train_text_lst[i] for i in train_idx_selected]\n",
    "train_label_lst = [train_label_lst[i] for i in train_idx_selected]\n",
    "\n",
    "# remove samples with few class occurences in test set\n",
    "test_idx_selected, test_label_lst = remove_minor_class(_test_text_lst, _test_label_lst, topics_selected)\n",
    "test_text_lst = [_test_text_lst[i] for i in test_idx_selected]\n",
    "test_label_lst = [test_label_lst[i] for i in test_idx_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7773, 77)\n",
      "(3016, 77)\n"
     ]
    }
   ],
   "source": [
    "# label transformer\n",
    "from sklearn import preprocessing\n",
    "label_binarizer = preprocessing.MultiLabelBinarizer(topics_selected)\n",
    "label_binarizer.fit(train_label_lst)\n",
    "# transform training label\n",
    "y_train = label_binarizer.transform(train_label_lst)\n",
    "print(y_train.shape)\n",
    "# transform testing label\n",
    "y_test = label_binarizer.transform(test_label_lst)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 23545)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "x_train = vect.fit_transform(train_text_lst)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class LemmaTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (lemmatizer.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model building + grid search + evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model, svm, naive_bayes, model_selection, metrics\n",
    "class LRModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('cls', OneVsRestClassifier(linear_model.LogisticRegression()))\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        \"cls__estimator__C\": [0.01, 0.1, 1],\n",
    "    }\n",
    "    \n",
    "class NBModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', LemmaTfidfVectorizer(stop_words='english')),\n",
    "        ('cls', OneVsRestClassifier(naive_bayes.MultinomialNB(\n",
    "            fit_prior=True, class_prior=None))),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'cls__estimator__alpha': (1e-2, 1e-3)\n",
    "    }\n",
    "    \n",
    "class SVCModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('cls', OneVsRestClassifier(svm.LinearSVC())),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'cls__estimator__C': [0.01, 0.1, 1]        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "class XGBModel(object):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "        ('cls', OneVsRestClassifier(XGBClassifier())),\n",
    "    ])   \n",
    "    parameters = {\n",
    "        'vectorizer__max_df': (0.5, 0.75),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],        \n",
    "        'cls__estimator__max_depth': [3, 11],\n",
    "        'cls__estimator__subsample': [0.25, 0.5, 0.75],\n",
    "        'cls__estimator__colsample_bytree': [0.25, 0.5, 0.75]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.7538071065989848, total=   9.5s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.7387777176852351, total=   9.5s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.698163665537529, total=   9.6s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.75428777757718, total=  18.3s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.7696577243293247, total=  16.0s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   40.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.7314881380301941, total=  16.0s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.7387224828581739, total=   8.5s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7493133125801135, total=  27.3s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.7532656023222062, total=   8.7s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.6985543458861323, total=   9.2s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7615298087739032, total=  28.7s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7248444932308817, total=  31.2s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.7533453887884269, total=  23.6s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.768888888888889, total=  25.1s\n",
      "[CV] cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.7308730873087308, total=  25.3s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.7139944392956441, total=  12.1s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.7304380381879445, total=  15.8s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7491749174917491, total=  41.7s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.5, score=0.672962962962963, total=  14.2s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7616366366366366, total=  49.9s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.01, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7252747252747253, total=  48.6s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.7692307692307693, total=  32.4s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.7738031678234562, total=  33.4s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.5, score=0.7438499913985893, total=  33.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.713888373817912, total=  15.8s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7702033145395523, total=  56.5s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.7304380381879445, total=  17.8s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 1), vectorizer__max_df=0.75, score=0.6730840429470566, total=  17.1s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7772895060643347, total=  57.7s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.5, score=0.7487318227933717, total=  59.0s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.7691505992704533, total=  41.0s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.7736654804270463, total=  45.8s\n",
      "[CV] cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75 \n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 2), vectorizer__max_df=0.75, score=0.7438499913985893, total=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 out of  36 | elapsed:  6.3min remaining:   34.6s\n",
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7707300393229611, total= 1.1min\n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7770745428973277, total= 1.0min\n",
      "[CV]  cls__estimator__alpha=0.001, vectorizer__ngram_range=(1, 3), vectorizer__max_df=0.75, score=0.7479261892669714, total=  58.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  36 out of  36 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('vectorizer', LemmaTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "           lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "           ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "           smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "           sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "           tokenizer=None, use_idf=True, vocabulary=None)), ('cls', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True),\n",
      "          n_jobs=1))]\n",
      "Perform best classifier on test data:\n"
     ]
    }
   ],
   "source": [
    "mid = 'NBModelLemmatizer'\n",
    "pipeline, parameters = NBModel.pipeline, NBModel.parameters\n",
    "grid_search = model_selection.GridSearchCV(pipeline, parameters, scoring='f1_micro', cv=None, n_jobs=4, verbose=10)\n",
    "grid_search.fit(train_text_lst, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search.best_estimator_.steps)\n",
    "\n",
    "print(\"Perform best classifier on test data:\")\n",
    "best_clf = grid_search.best_estimator_\n",
    "predictions = best_clf.predict(test_text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "     steps=[('vectorizer', LemmaTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 3), norm='l2', preprocessor=None,...sifier(estimator=MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1))])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          sugar       1.00      0.72      0.84        36\n",
      "            jet       0.00      0.00      0.00         1\n",
      "            gas       1.00      0.35      0.52        17\n",
      "        soybean       0.56      0.30      0.39        33\n",
      "           alum       1.00      0.13      0.23        23\n",
      "            hog       1.00      0.33      0.50         6\n",
      "          crude       0.84      0.73      0.78       189\n",
      "            oat       1.00      0.17      0.29         6\n",
      "          cocoa       0.90      0.50      0.64        18\n",
      "       rape-oil       0.00      0.00      0.00         3\n",
      "            stg       0.00      0.00      0.00         0\n",
      "         barley       0.60      0.43      0.50        14\n",
      "           lead       1.00      0.07      0.13        14\n",
      "        veg-oil       0.78      0.49      0.60        37\n",
      "         income       1.00      0.29      0.44         7\n",
      "         retail       1.00      0.50      0.67         2\n",
      "         rubber       0.88      0.58      0.70        12\n",
      "    inventories       0.00      0.00      0.00         0\n",
      "         lumber       0.00      0.00      0.00         6\n",
      "        soy-oil       0.50      0.09      0.15        11\n",
      "           fuel       0.60      0.30      0.40        10\n",
      "        plywood       0.00      0.00      0.00         0\n",
      "         copper       0.55      0.33      0.41        18\n",
      "         coffee       0.84      0.75      0.79        28\n",
      "       pet-chem       1.00      0.08      0.15        12\n",
      "         silver       1.00      0.12      0.22         8\n",
      "           zinc       1.00      0.08      0.14        13\n",
      "            tin       1.00      0.42      0.59        12\n",
      "            gnp       0.80      0.80      0.80        35\n",
      "strategic-metal       1.00      0.09      0.17        11\n",
      "       interest       0.72      0.55      0.62       133\n",
      "          grain       0.78      0.72      0.75       149\n",
      "            acq       0.97      0.84      0.90       719\n",
      "        sun-oil       0.00      0.00      0.00         2\n",
      "           corn       0.50      0.50      0.50        56\n",
      "      meal-feed       0.83      0.26      0.40        19\n",
      "       rapeseed       1.00      0.44      0.62         9\n",
      "      groundnut       0.00      0.00      0.00         4\n",
      "        housing       1.00      0.25      0.40         4\n",
      "        coconut       0.00      0.00      0.00         2\n",
      "        oilseed       0.47      0.40      0.44        47\n",
      "         nickel       0.00      0.00      0.00         1\n",
      "    coconut-oil       1.00      0.33      0.50         3\n",
      "         orange       1.00      0.36      0.53        11\n",
      "       reserves       0.90      0.50      0.64        18\n",
      "            dlr       0.39      0.52      0.45        44\n",
      "         cotton       0.71      0.25      0.37        20\n",
      "        austdlr       0.00      0.00      0.00         0\n",
      "            cpi       0.57      0.46      0.51        28\n",
      "            lei       1.00      0.67      0.80         3\n",
      "       l-cattle       0.00      0.00      0.00         2\n",
      "            bop       0.65      0.50      0.57        30\n",
      "           heat       0.75      0.60      0.67         5\n",
      "   money-supply       0.63      0.50      0.56        34\n",
      "      livestock       0.60      0.38      0.46        24\n",
      "            tea       0.00      0.00      0.00         4\n",
      "            wpi       0.86      0.60      0.71        10\n",
      "    instal-debt       0.00      0.00      0.00         1\n",
      "           earn       0.98      0.94      0.96      1088\n",
      "       soy-meal       0.33      0.08      0.12        13\n",
      "       money-fx       0.70      0.72      0.71       180\n",
      "       palm-oil       1.00      0.60      0.75        10\n",
      "        carcass       0.71      0.28      0.40        18\n",
      "           ship       0.85      0.64      0.73        89\n",
      "     iron-steel       0.83      0.36      0.50        14\n",
      "          wheat       0.61      0.70      0.65        71\n",
      "        sunseed       1.00      0.20      0.33         5\n",
      "           jobs       1.00      0.43      0.60        21\n",
      "            dmk       0.00      0.00      0.00         4\n",
      "           gold       0.92      0.40      0.56        30\n",
      "            yen       0.25      0.07      0.11        14\n",
      "            ipi       0.83      0.42      0.56        12\n",
      "        sorghum       0.67      0.20      0.31        10\n",
      "        nat-gas       0.61      0.37      0.46        30\n",
      "           rice       0.50      0.08      0.14        24\n",
      "          trade       0.56      0.66      0.60       117\n",
      "       platinum       0.00      0.00      0.00         7\n",
      "\n",
      "    avg / total       0.84      0.71      0.75      3721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieuhuynh/Apps/anaconda3/envs/text-cls-py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(y_test, predictions, target_names=topics_selected)\n",
    "print(report)\n",
    "with(open(os.path.join(os.getcwd(), '{}.txt'.format(mid)), 'w')) as f:\n",
    "    f.write('Best params: ' + str(best_clf.get_params))\n",
    "    f.write('\\n--------------\\n')\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
